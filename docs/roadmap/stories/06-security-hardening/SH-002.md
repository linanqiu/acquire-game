# SH-002: Rate Limit REST Endpoints

## Metadata
- **Epic**: Security Hardening
- **Status**: `not-started`
- **Priority**: `high`
- **Effort**: `S` (30-60m)
- **Dependencies**: None

## Context

The backend has a `RateLimiter` class but it's only applied to WebSocket message handling. REST endpoints (`/create`, `/join`, `/start`, `/add-bot`) have no rate limiting, making them vulnerable to abuse.

```python
# Existing rate limiter in main.py
rate_limiter = RateLimiter(max_requests=10, window_seconds=1)
# Only used in player_websocket handler
```

## Requirements

1. Apply rate limiting to all REST endpoints
2. Use appropriate limits per endpoint type
3. Return 429 Too Many Requests when exceeded
4. Include Retry-After header in response

## Acceptance Criteria

- [ ] `/create` endpoint rate limited (e.g., 5 requests/minute per IP)
- [ ] `/join` endpoint rate limited (e.g., 10 requests/minute per IP)
- [ ] `/room/{code}/start` rate limited (e.g., 3 requests/minute per room)
- [ ] `/room/{code}/add-bot` rate limited (e.g., 10 requests/minute per room)
- [ ] 429 response includes Retry-After header
- [ ] Rate limit state persists across requests (not per-request instantiation)
- [ ] Tests verify rate limiting behavior

## Implementation Notes

### Option 1: FastAPI Dependency

```python
from fastapi import Request, HTTPException
from collections import defaultdict
import time

class IPRateLimiter:
    def __init__(self, max_requests: int, window_seconds: int):
        self.max_requests = max_requests
        self.window_seconds = window_seconds
        self.requests: dict[str, list[float]] = defaultdict(list)

    async def __call__(self, request: Request):
        client_ip = request.client.host
        now = time.time()

        # Clean old requests
        self.requests[client_ip] = [
            t for t in self.requests[client_ip]
            if now - t < self.window_seconds
        ]

        if len(self.requests[client_ip]) >= self.max_requests:
            retry_after = self.window_seconds - (now - self.requests[client_ip][0])
            raise HTTPException(
                status_code=429,
                detail="Too many requests",
                headers={"Retry-After": str(int(retry_after))}
            )

        self.requests[client_ip].append(now)

# Usage
create_limiter = IPRateLimiter(max_requests=5, window_seconds=60)

@app.post("/create")
async def create_room(player_name: str = Form(...), _: None = Depends(create_limiter)):
    ...
```

### Option 2: slowapi Library

```python
from slowapi import Limiter
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter

@app.post("/create")
@limiter.limit("5/minute")
async def create_room(request: Request, player_name: str = Form(...)):
    ...
```

### Recommended Limits

| Endpoint | Limit | Rationale |
|----------|-------|-----------|
| `/create` | 5/min | Prevents room spam |
| `/join` | 10/min | Allow retries on failure |
| `/start` | 3/min | Game start is infrequent |
| `/add-bot` | 10/min | May add multiple bots |

## Verification

```bash
# Run rate limit tests
cd backend && pytest tests/test_rate_limiting.py -v

# Manual test - should get 429 after 5 requests
for i in {1..10}; do
  curl -s -o /dev/null -w "%{http_code}\n" -X POST \
    -d "player_name=test$i" http://localhost:8000/create
done
```

## Notes

- Consider using Redis for distributed rate limiting in production
- Current in-memory approach works for single-instance deployment
