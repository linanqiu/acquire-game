# AI-001: MCTS Basic Implementation

## Metadata
- **Epic**: AI Training
- **Status**: `not-started`
- **Priority**: `high`
- **Effort**: `L` (2-4 hours)
- **Dependencies**: None (uses existing game.py)

## Context

Implement a basic Monte Carlo Tree Search bot. MCTS provides strong play without machine learning, using simulation to evaluate moves. This is the first step toward neural bot training.

## Requirements

1. Implement MCTS algorithm
2. Use existing `Game.clone()` for simulation
3. Use `Rules.get_all_legal_actions()` for moves
4. Configurable simulation count
5. Random rollout policy

> **Note**: Verify actual Game/Rules API signatures before implementing. Code examples below are directional guidance.

## Acceptance Criteria

- [ ] MCTSBot class implements choose_action()
- [ ] Configurable simulation count (default 1000)
- [ ] Uses game cloning for simulation
- [ ] Random rollout to game end
- [ ] Returns action with highest win rate
- [ ] Move time <5 seconds with 1000 sims
- [ ] Beats hard bot >50% of games
- [ ] Unit tests for core MCTS logic

## Implementation Notes

### File to Create

**backend/game/mcts_bot.py**:
```python
import random
import math
from typing import Optional
from .game import Game
from .action import Action
from .rules import Rules


class MCTSBot:
    """Monte Carlo Tree Search bot for Acquire."""

    def __init__(self, simulations: int = 1000, seed: Optional[int] = None):
        self.simulations = simulations
        self.rng = random.Random(seed)

    def choose_action(self, game: Game, player_id: str) -> Action:
        """Choose best action using MCTS."""
        legal_actions = Rules.get_all_legal_actions(game, player_id)

        if not legal_actions:
            raise ValueError("No legal actions available")

        if len(legal_actions) == 1:
            return legal_actions[0]

        # Run simulations for each action
        action_scores = {}
        for action in legal_actions:
            wins = 0
            for _ in range(self.simulations // len(legal_actions)):
                wins += self._simulate(game, player_id, action)
            action_scores[action] = wins

        # Return best action
        best_action = max(action_scores, key=action_scores.get)
        return best_action

    def _simulate(self, game: Game, player_id: str, action: Action) -> float:
        """Run one simulation from the given action."""
        from .game import GamePhase

        # Clone game and apply action
        sim_game = game.clone()
        sim_game.apply_action(player_id, action)

        # Random rollout to completion
        while sim_game.phase != GamePhase.GAME_OVER:
            current_player = sim_game.get_current_player()
            if not current_player:
                break
            actions = Rules.get_all_legal_actions(sim_game, current_player.player_id)

            if not actions:
                break

            random_action = self.rng.choice(actions)
            sim_game.apply_action(current_player.player_id, random_action)

        # Score: 1 for win, 0.5 for tie, 0 for loss
        # Use winners list from game
        if sim_game.winners:
            winner_ids = [w.player_id for w in sim_game.winners]
            if player_id in winner_ids:
                return 1.0 if len(winner_ids) == 1 else 0.5
        return 0.0


class MCTSNode:
    """Node in MCTS tree for future enhancement."""

    def __init__(self, parent=None, action=None):
        self.parent = parent
        self.action = action
        self.children = []
        self.visits = 0
        self.wins = 0

    def ucb1(self, exploration=1.41) -> float:
        """Upper Confidence Bound for action selection."""
        if self.visits == 0:
            return float('inf')
        exploitation = self.wins / self.visits
        exploration_term = exploration * math.sqrt(
            math.log(self.parent.visits) / self.visits
        )
        return exploitation + exploration_term
```

### Test File

**backend/tests/test_mcts_bot.py**:
```python
import pytest
from game.mcts_bot import MCTSBot
from game.game import Game


def test_mcts_returns_legal_action():
    game = Game()
    game.add_player("test", "Test")
    game.add_player("bot1", "Bot1")
    game.add_player("bot2", "Bot2")
    game.start_game()

    bot = MCTSBot(simulations=100)
    action = bot.choose_action(game, "test")

    assert action is not None


def test_mcts_vs_hard_bot():
    """MCTS should beat hard bot at least 50% of the time."""
    wins = 0
    games = 20

    for _ in range(games):
        # Run game MCTS vs hard bots
        # Count wins
        pass

    assert wins >= games * 0.5
```

## Verification

```bash
cd backend
python -m pytest tests/test_mcts_bot.py -v

# Benchmark
python -c "
from game.mcts_bot import MCTSBot
from game.game import Game
import time

game = Game()
game.add_player('p1', 'Player1')
game.add_player('p2', 'Bot1')
game.add_player('p3', 'Bot2')
game.start_game()

bot = MCTSBot(simulations=1000)
start = time.time()
action = bot.choose_action(game, 'p1')
print(f'1000 sims took {time.time() - start:.2f}s')
"
```

## Reference

- [AI Roadmap - MCTS](../../../ai/ROADMAP.md#phase-1-mcts-bot-search-based)
- [Existing bot.py](../../../backend/game/bot.py)
